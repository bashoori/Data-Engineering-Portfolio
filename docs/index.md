<table width="100%" style="vertical-align: middle;">
  <tr>
    <td style="vertical-align: middle;">
      <h1 style="margin-bottom: 0;">Bita Ashoori<br>
        <span style="font-size: 0.9em; font-weight: normal;">💼 Data Engineering Portfolio</span>
      </h1>
    </td>
    <td align="right" style="vertical-align: middle;">
      <img src="https://raw.githubusercontent.com/bashoori/repo/master/pp/IMG_9043.JPG" width="180" alt="Bita Ashoori" style="border-radius: 50%; margin-left: 20px;" />
    </td>
  </tr>
</table>
---

## About Me

I’m a Data Engineer based in Vancouver with over 5 years of experience across data engineering, business intelligence, and analytics. I specialize in building clean, cloud-native data pipelines and automating workflows that help organizations turn raw data into smart decisions. My current focus includes applying AI/ML principles to strengthen my cloud and analytics background.

I have 3+ years of experience building and maintaining cloud-based pipelines and 2+ years as a BI/ETL Developer. I’m skilled in Python, SQL, Apache Airflow, AWS (S3, Lambda, Redshift), and modern orchestration techniques.

## Contact Me 

💻 Explore my work on [GitHub](https://github.com/bashoori)  
🔗 Connect with me on [LinkedIn](https://www.linkedin.com/in/bitaashoori)  
📧 Contact me at [bitaashoori20@gmail.com](mailto:bitaashoori20@gmail.com)  
📄 [Download My Resume](https://github.com/bashoori/repo/blob/master/pp/BitaAshoori-DataEngineer-resume.pdf)

---

## Project Highlights  

### 🛠️ Airflow AWS Modernization  
📎 [GitHub Repo](https://github.com/bashoori/data-engineering-portfolio/tree/main/airflow-aws-modernization)  
🧰 **Stack**: Python, Apache Airflow, Docker, AWS S3  
🧪 **Tested On**: Local Docker, GitHub Codespaces  

Migrated legacy Windows Task Scheduler jobs into modular Airflow DAGs with Docker and AWS S3.  
✅ **Business Impact**: Reduced manual errors by 50% and improved job monitoring and reliability.

<p align="center">
  <img src="https://raw.githubusercontent.com/bashoori/repo/master/airflow-aws-modernization/etl2.png" alt="Airflow AWS Diagram" width="700" style="border: 1px solid #ccc; border-radius: 6px;" />
</p>

---

### ⚡ Real-Time Marketing Pipeline  
📎 [GitHub Repo](https://github.com/bashoori/data-engineering-portfolio/tree/main/real-time-marketing-pipeline)  
🧰 **Stack**: PySpark, Databricks, GitHub Actions, AWS S3  
🧪 **Tested On**: Databricks Community Edition, GitHub CI/CD  

Simulates real-time ingestion of campaign data, transforming and storing insights using PySpark and Delta Lake.  
✅ **Business Impact**: Reduced reporting lag from 24 hours to 1 hour for faster insights.

<p align="center">
  <img src="https://raw.githubusercontent.com/bashoori/repo/master/real-time-marketing-pipeline/image1.png" alt="Real-Time Pipeline Diagram" width="700" style="border: 1px solid #ccc; border-radius: 6px;" />
</p>

---

### ☁️ Cloud ETL Modernization  
📎 [GitHub Repo](https://github.com/bashoori/data-engineering-portfolio/tree/main/cloud-etl-modernization-airflow-aws)  
🧰 **Stack**: Apache Airflow, AWS Redshift, CloudWatch  
🧪 **Tested On**: AWS Free Tier, Docker  

Built a scalable and maintainable ETL pipeline for structured data movement from APIs to Redshift with alerting via CloudWatch.  
✅ **Business Impact**: Improved troubleshooting speed by 30% with better logging and visibility.

<p align="center">
  <img src="https://raw.githubusercontent.com/bashoori/repo/master/cloud-etl-Modernization/etl31.png" alt="Cloud ETL Diagram" width="700" style="border: 1px solid #ccc; border-radius: 6px;" />
</p>

---

### 🏥 FHIR Healthcare Pipeline  
📎 [GitHub Repo](https://github.com/bashoori/data-engineering-portfolio/tree/main/healthcare-FHIR-data-pipeline)  
🧰 **Stack**: Python, Pandas, Synthea, SQLite, Streamlit  
🧪 **Tested On**: Local + Streamlit + BigQuery-compatible  

Processes synthetic healthcare records in FHIR JSON format and converts them into clean, queryable relational tables.  
✅ **Business Impact**: Reduced preprocessing time by 60% and prepared the data for ML/analytics readiness.

<p align="center">
  <img src="https://raw.githubusercontent.com/bashoori/repo/master/healthcare-FHIR-data-pipeline/etl4.png" alt="FHIR Pipeline Diagram" width="700" style="border: 1px solid #ccc; border-radius: 6px;" />
</p>

---

### 🔍 LinkedIn Scraper (Lambda)  
📎 [GitHub Repo](https://github.com/bashoori/data-engineering-portfolio/tree/main/linkedIn-job-scraper)  
🧰 **Stack**: AWS Lambda, EventBridge, BeautifulSoup, S3, CloudWatch  
🧪 **Tested On**: AWS Free Tier  

Automates job scraping from LinkedIn using serverless AWS Lambda and stores structured output in S3.  
✅ **Business Impact**: Streamlined job research and enabled structured outreach analysis.

<p align="center">
  <img src="https://raw.githubusercontent.com/bashoori/repo/master/linkedIn-job-scraper/etl5.png" alt="LinkedIn Scraper Diagram" width="700" style="border: 1px solid #ccc; border-radius: 6px;" />
</p>

---

### 📈 PySpark Sales Pipeline  
📎 [GitHub Repo](https://github.com/bashoori/data-engineering-portfolio/tree/main/pyspark-sales-pipeline)  
🧰 **Stack**: PySpark, Delta Lake, AWS S3  
🧪 **Tested On**: Local Databricks + S3  

A production-ready PySpark ETL that ingests and transforms high-volume sales data into Delta Lake for BI.  
✅ **Business Impact**: Improved reporting accuracy and cut transformation runtime by over 40%.

<p align="center">
  <img src="https://raw.githubusercontent.com/bashoori/repo/master/pyspark-sales-pipeline/etl6.png" alt="PySpark Pipeline Diagram" width="700" style="border: 1px solid #ccc; border-radius: 6px;" />
</p>

---

